{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "12521030",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iniciando Protocolo de Entrenamiento - Proyecto Wow...\n",
      "Clases detectadas: ['Anemia' 'Infection' 'Normal' 'Thrombocytopenia']\n",
      "\n",
      "Comenzando Stratified K-Fold (5 Folds)...\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\matir\\ml_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [02:02:24] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Fold 1: Accuracy=0.9987 | F1-Weighted=0.9987\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\matir\\ml_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [02:02:25] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Fold 2: Accuracy=0.9987 | F1-Weighted=0.9987\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\matir\\ml_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [02:02:25] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Fold 3: Accuracy=0.9980 | F1-Weighted=0.9980\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\matir\\ml_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [02:02:25] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Fold 4: Accuracy=0.9980 | F1-Weighted=0.9980\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\matir\\ml_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [02:02:25] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Fold 5: Accuracy=0.9967 | F1-Weighted=0.9967\n",
      "------------------------------------------------------------\n",
      "Promedio F1-Weighted: 0.9980 (+/- 0.0007)\n",
      "\n",
      "Entrenando modelo final con TODOS los datos...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\matir\\ml_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [02:02:26] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Modelo guardado como 'xgboost_clinical_v1.json'\n",
      "\n",
      " Reporte de Clasificaci贸n (Training Set - Sanity Check):\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "          Anemia       1.00      1.00      1.00      1060\n",
      "       Infection       1.00      1.00      1.00       440\n",
      "          Normal       1.00      1.00      1.00      5792\n",
      "Thrombocytopenia       1.00      1.00      1.00       235\n",
      "\n",
      "        accuracy                           1.00      7527\n",
      "       macro avg       1.00      1.00      1.00      7527\n",
      "    weighted avg       1.00      1.00      1.00      7527\n",
      "\n",
      "Pipeline finalizado. Listo para Fase 4 (Explicabilidad).\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, classification_report, f1_score, confusion_matrix\n",
    "import joblib\n",
    "\n",
    "def train_model():\n",
    "    print(\"Iniciando Protocolo de Entrenamiento - Proyecto Wow...\")\n",
    "    \n",
    "    # 1. Cargar Datos\n",
    "    try:\n",
    "        df = pd.read_csv(\"nhanes_labeled_data.csv\")\n",
    "    except FileNotFoundError:\n",
    "        print(\"Error: Falta 'nhanes_labeled_data.csv'\")\n",
    "        return\n",
    "\n",
    "    # 2. Preprocesamiento\n",
    "    # Separamos Features (X) y Target (y)\n",
    "    # Eliminamos 'ID' porque es un identificador, no un predictor (evitar overfitting espurio)\n",
    "    X = df.drop(columns=['Diagnosis', 'ID']) \n",
    "    y_raw = df['Diagnosis']\n",
    "    \n",
    "    # Codificar Target (Texto -> N煤meros)\n",
    "    # XGBoost necesita 0, 1, 2, 3...\n",
    "    le = LabelEncoder()\n",
    "    y = le.fit_transform(y_raw)\n",
    "    \n",
    "    # Guardamos el encoder para que la App sepa qu茅 es 0, 1, 2...\n",
    "    joblib.dump(le, 'label_encoder.joblib')\n",
    "    print(f\"Clases detectadas: {le.classes_}\")\n",
    "\n",
    "    # 3. Configuraci贸n del Modelo (XGBoost Classifier)\n",
    "    # Usamos 'scale_pos_weight' impl铆cito o m茅tricas logloss para multiclase\n",
    "    model = xgb.XGBClassifier(\n",
    "        objective='multi:softprob', # Probabilidad para cada clase\n",
    "        num_class=len(le.classes_), # 4 clases\n",
    "        eval_metric='mlogloss',\n",
    "        use_label_encoder=False,\n",
    "        random_state=42,\n",
    "        n_estimators=100,           # rboles\n",
    "        max_depth=4,                # Profundidad (evitar overfitting)\n",
    "        learning_rate=0.1\n",
    "    )\n",
    "\n",
    "    # 4. Validaci贸n Cruzada Estratificada (Mandamiento #4)\n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    \n",
    "    f1_scores = []\n",
    "    recalls = []\n",
    "    \n",
    "    print(\"\\nComenzando Stratified K-Fold (5 Folds)...\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    fold = 1\n",
    "    for train_index, test_index in skf.split(X, y):\n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        \n",
    "        # Entrenar\n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        # Predecir\n",
    "        y_pred = model.predict(X_test)\n",
    "        \n",
    "        # M茅tricas del Fold\n",
    "        # Usamos 'weighted' para dar peso seg煤n la cantidad de ejemplos reales\n",
    "        f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "        acc = accuracy_score(y_test, y_pred)\n",
    "        \n",
    "        f1_scores.append(f1)\n",
    "        \n",
    "        print(f\" Fold {fold}: Accuracy={acc:.4f} | F1-Weighted={f1:.4f}\")\n",
    "        fold += 1\n",
    "\n",
    "    print(\"-\" * 60)\n",
    "    print(f\"Promedio F1-Weighted: {np.mean(f1_scores):.4f} (+/- {np.std(f1_scores):.4f})\")\n",
    "    \n",
    "    # 5. Entrenamiento Final (Full Data) y Reporte Detallado\n",
    "    print(\"\\nEntrenando modelo final con TODOS los datos...\")\n",
    "    model.fit(X, y)\n",
    "    \n",
    "    # Guardamos el modelo\n",
    "    model.save_model(\"xgboost_clinical_v1.json\")\n",
    "    print(\" Modelo guardado como 'xgboost_clinical_v1.json'\")\n",
    "    \n",
    "    # Reporte de Confusi贸n (Sobre todo el dataset para ver debilidades)\n",
    "    # OJO: Esto es 'evaluaci贸n en train' (solo informativo, ya validamos con CV)\n",
    "    final_preds = model.predict(X)\n",
    "    print(\"\\n Reporte de Clasificaci贸n (Training Set - Sanity Check):\")\n",
    "    print(classification_report(y, final_preds, target_names=le.classes_))\n",
    "    \n",
    "    print(\"Pipeline finalizado. Listo para Fase 4 (Explicabilidad).\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    train_model()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ml_env)",
   "language": "python",
   "name": "ml_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
